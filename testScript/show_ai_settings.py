#!/usr/bin/env python3
"""
Show Current AI Settings
Display the current AI analysis trigger conditions
"""

from ai_config import AIConfig

def show_current_settings():
    """Show current AI analysis settings"""
    print("Current AI Analysis Trigger Conditions")
    print("=" * 42)
    
    config = AIConfig()
    settings = config.get_analysis_settings()
    
    print("ğŸ¯ TRIGGER CONDITIONS:")
    print(f"  Minimum data length: {settings.get('min_data_length', 4)} bytes")
    print(f"  Maximum data length: {settings.get('max_data_length', 1024)} bytes")
    print(f"  Analysis delay: {settings.get('analysis_delay_ms', 1000)}ms")
    print(f"  Rate limit: {settings.get('rate_limit_per_minute', 20)} requests/minute")
    
    print("\nğŸ§  ANALYSIS TYPES:")
    print(f"  Protocol analysis: {'âœ…' if settings.get('analyze_protocol', True) else 'âŒ'}")
    print(f"  Error detection: {'âœ…' if settings.get('analyze_errors', True) else 'âŒ'}")
    print(f"  Pattern recognition: {'âœ…' if settings.get('analyze_patterns', True) else 'âŒ'}")
    print(f"  Auto analysis: {'âœ…' if settings.get('auto_analysis', True) else 'âŒ'}")
    
    print("\nâš¡ API SETTINGS:")
    print(f"  Model: {settings.get('model', 'gpt-3.5-turbo')}")
    print(f"  Max tokens: {settings.get('max_tokens', 500)}")
    print(f"  Temperature: {settings.get('temperature', 0.3)}")
    
    print("\nğŸ“‹ WHAT TRIGGERS AI ANALYSIS:")
    print("  âœ… ANY RX data â‰¥ 4 bytes")
    print("  âœ… After 1000ms delay from last analysis")
    print("  âœ… When AI Analysis is enabled")
    print("  âœ… When rate limit allows (20/minute)")
    
    print("\nâŒ WHAT DOESN'T TRIGGER:")
    print("  âŒ TX (transmitted) data")
    print("  âŒ Data < 4 bytes")
    print("  âŒ When AI Analysis is disabled")
    print("  âŒ When rate limited")
    print("  âŒ Within 1000ms of previous analysis")

if __name__ == "__main__":
    show_current_settings()